{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e09d41",
   "metadata": {},
   "source": [
    "First, download the full dataset (1 million rows) as a zip from this [Kaggle link](https://www.kaggle.com/datasets/sridharstreaks/insurance-data-for-machine-learning). Then unzip it to a .csv. Load that .csv into a table and name it INSURANCE_FULL_DATASET. We will pull from that table to create a training data table and our incoming \"streamed\" data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7fed8-d873-4707-93d7-d8d7e46801bb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Read the entire table into a Snowpark DataFrame\n",
    "snowpark_df = session.table('INSURANCE.ML_PIPE.INSURANCE_FULL_DATASET')\n",
    "\n",
    "# Convert the Snowpark DF to a Pandas DataFrame\n",
    "insurance_df = snowpark_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde22f4-f7f3-4f17-80f3-19e7399811bf",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Capitalize column names\n",
    "insurance_df.columns = insurance_df.columns.str.upper()\n",
    "\n",
    "# Rearrange columns to fit target schema\n",
    "cols = insurance_df.columns.tolist()\n",
    "cols = cols[:3] + cols[-1:] + cols[3:-1]\n",
    "insurance_df = insurance_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the 10k records to the 'SOURCE_OF_TRUTH' table\n",
    "source_of_truth_df = session.write_pandas(insurance_df[:10000], table_name='SOURCE_OF_TRUTH',database='INSURANCE',schema='ML_PIPE',auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137111d-ef9c-4bad-8e49-4edfbfe3189c",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "# Write the remaining 990k records to the 'INCOMING_DATA_SOURCE' table\n",
    "incoming_data_source_df = session.write_pandas(insurance_df[10000:], table_name='INCOMING_DATA_SOURCE',database='INSURANCE',schema='ML_PIPE',auto_create_table=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "dan.monica.smith@gmail.com",
   "authorId": "8939921151237",
   "authorName": "SPORTY4992",
   "lastEditTime": 1738172475408,
   "notebookId": "zxwxd3mothe7zshsbwod",
   "sessionId": "b705b03e-71a1-41b1-bbef-c67845cd9846"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
